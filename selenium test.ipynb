{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "\n",
    "# CONFIGURATION\n",
    "website = #website\n",
    "email = #email\n",
    "pword = #password\n",
    "people_count = 30 # over-shoots the number of chart elements, this forgoes trying to figure out how many people should be on the list\n",
    "day_count = 10 # how many days' worth of data are being scraped, going backwards in time\n",
    "log_path = r\"C:\\Users\\Alex\\Desktop\\python\\countit_logs\"\n",
    "\n",
    "# XPATH LOCATIONS\n",
    "login_xpath = '/html/body/div[2]/div[2]/div[1]/div/div/div[3]/div/form/div[3]/div[1]/button'\n",
    "timing_toggle_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[1]/div/div[1]'\n",
    "timing_option_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[1]/div/div[1]/ul/li[3]'\n",
    "points_toggle_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[3]/div/div'\n",
    "points_option_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[3]/div/ul/li[4]/a'\n",
    "chart_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[3]/div/div[2]/div[3]/div/div[2]/div/div'\n",
    "date_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[1]/div/div[2]/div/div[2]/div/div'\n",
    "date_back_xpath = '/html/body/div[2]/div[2]/div[1]/div/div[1]/div[1]/div/div[3]/div/div/div[2]/div[1]/div[1]/div/div[2]/div/div[1]/i'\n",
    "\n",
    "# FUNCTIONS\n",
    "def date_converter(date_value):\n",
    "    # converts scraped date into MM/DD/YYYY with the current year, so \"APR 5\" becomes \"04/05/2021\"\n",
    "    month, day = date_value.strip().split()\n",
    "    month_dict = {'JAN':'01','FEB':'02','MAR':'03',\n",
    "                  'APR':'04','MAY':'05','JUN':'06',\n",
    "                  'JUL':'07','AUG':'08','SEP':'09',\n",
    "                  'OCT':'10','NOV':'11','DEC':'12'}\n",
    "    day = ('0' + day)[-2:]\n",
    "    month = month_dict[month]\n",
    "    year = datetime.now().year\n",
    "    datestamp = f\"{month}/{day}/{year}\"\n",
    "    return datestamp\n",
    "\n",
    "def scrape_chart(chart_xpath, people_count):\n",
    "    # Iterates through the chart and reads the text for each bar\n",
    "    result_list = []\n",
    "    for i in range(people_count):\n",
    "        try:\n",
    "            chart_element = driver.find_element_by_xpath(chart_xpath + f\"/div[{i}]\")\n",
    "            result_list.append(chart_element.text)\n",
    "        except:\n",
    "            pass\n",
    "    return result_list\n",
    "\n",
    "def scrape_parser(scraped_dict):\n",
    "    # This reads the raw text scraped from the website and builds a clean \"Day,Name,Points\" string for the data base\n",
    "    parsed_entries = []\n",
    "    for date, elements in scraped_dict.items():\n",
    "        for person in elements:\n",
    "            if person.split('\\n')[-1].isnumeric(): # the rows we want end with a linebreak followed by a number, e.g. '\\n135'\n",
    "                name, points = person[person.index('.') + 1 :].split('\\n') # strips out the leading rank indicator, e.g. '3. '\n",
    "                name = name.encode('ascii', 'ignore').decode('ascii').strip('.').strip() # cleans up the name, also removing emojis and weird chars\n",
    "                entry = f\"{date},{name},{points}\" # this our entry into the data file\n",
    "                parsed_entries.append(entry)\n",
    "    return parsed_entries\n",
    "\n",
    "def write_parsed_log(log_path, parsed_entries):\n",
    "    # Writes a new log file with the parsed data\n",
    "    file_name = 'countit_data_' + datetime.now().strftime(\"%Y%m%d%H%M%S\") + '.txt' # file name has timestamp in the name make it unique\n",
    "    file_path = log_path + \"\\\\\" + file_name\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for entry in parsed_entries:\n",
    "            file.write(entry + '\\n')\n",
    "        file.close()\n",
    "\n",
    "# MAIN\n",
    "if __name__ == '__main__':\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window() #xpath behaves weirdly for small windows\n",
    "    driver.get(website)\n",
    "\n",
    "    # Log in using credentials in config\n",
    "    driver.find_element_by_id('email').send_keys(email)\n",
    "    driver.find_element_by_id('password').send_keys(pword)\n",
    "    time.sleep(1) # wait for login button to appear\n",
    "    driver.find_element_by_xpath(login_xpath).click()\n",
    "    time.sleep(2) # let new page load\n",
    "\n",
    "    # Toggle options to be DAILY points\n",
    "    driver.find_element_by_xpath(timing_toggle_xpath).click()\n",
    "    time.sleep(1) # wait for drop-down to load\n",
    "    driver.find_element_by_xpath(timing_option_xpath).click()\n",
    "\n",
    "    # Toggle options to be TOTAL points\n",
    "    driver.find_element_by_xpath(points_toggle_xpath).click()\n",
    "    time.sleep(1) # wait for drop-down to load\n",
    "    driver.find_element_by_xpath(points_option_xpath).click()\n",
    "\n",
    "    # Scrape the data for the past few days and put it in a dict by day\n",
    "    scraped_dict = {}\n",
    "    for _ in range(day_count):\n",
    "        time.sleep(1) # wait to let data load\n",
    "        \n",
    "        # create a datestamp for the current displayed data\n",
    "        date_value = driver.find_element_by_xpath(date_xpath)\n",
    "        datestamp = date_converter(date_value.text) \n",
    "        \n",
    "        scraped_dict[datestamp] = scrape_chart(chart_xpath, people_count) # scrape the data and enter into dict by date\n",
    "\n",
    "        driver.find_element_by_xpath(date_back_xpath).click() # toggle to the previous day\n",
    "    \n",
    "    # Parse the raw text and create a new log file for it\n",
    "    parsed_entries = scrape_parser(scraped_dict)\n",
    "    driver.quit()\n",
    "    write_parsed_log(log_path, parsed_entries)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_db(db_name, table_list, print_log = False):\n",
    "    import sqlite3\n",
    "    connection = sqlite3.connect(db_name)\n",
    "    cursor = connection.cursor()\n",
    "    table_check = [str(row).strip('(').strip(')').strip(',').strip(r\"'\") for row in cursor.execute('''SELECT name FROM sqlite_master WHERE type=\"table\"''')]\n",
    "    log = [f'Table check for {db_name}:']\n",
    "    table_count = 0\n",
    "    for table, create in table_list.items():\n",
    "        if table in table_check:\n",
    "            log.append(f\"Already exists: {table}\")\n",
    "            table_count += 1\n",
    "        else:\n",
    "            try:\n",
    "                cursor.execute(create)\n",
    "            except:\n",
    "                log.append(f\"Failed to add: {table}\")\n",
    "            else:\n",
    "                log.append(f\"Added: {table}\")\n",
    "                table_count += 1\n",
    "    log.append(f\"{table_count} of {len(table_list)} tables accounted for.\")\n",
    "    if print_log is True:\n",
    "        for line in log:\n",
    "            print(line)\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'countit.db'\n",
    "table_list = {'daily_points':'''CREATE TABLE daily_points\n",
    "                    (p_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    alias TEXT NOT NULL,\n",
    "                    created_date TEXT NOT NULL,\n",
    "                    date TEXT NOT NULL,\n",
    "                    points TEXT)''',\n",
    "              'people':'''CREATE TABLE people\n",
    "                    (p_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    alias TEXT NOT NULL,\n",
    "                    name TEXT NOT NULL)'''}\n",
    "build_db(db_name, table_list, print_log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "log_file = \"countit_data_20210318194755.txt\"\n",
    "connection = sqlite3.connect(db_name)\n",
    "cursor = connection.cursor()\n",
    "with open(r\"C:\\Users\\Alex\\Desktop\\python\\countit_logs\\\\\" + log_file) as file:\n",
    "    while True:\n",
    "        entry = file.readline()\n",
    "        created_date = log_file.strip('.txt').split('_')[2]\n",
    "        if entry:\n",
    "            date, alias, points = entry.strip('\\n').split(',')\n",
    "            params = (alias, created_date, date, points)\n",
    "            cursor.execute(\"INSERT INTO daily_points VALUES (NULL, ?, ?, ?, ?)\", params)\n",
    "        else:\n",
    "            break\n",
    "    file.close()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "db_name = 'countit.db'\n",
    "connection = sqlite3.connect(db_name)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute('''SELECT * FROM daily_points WHERE alias = \"Alex B\"''')\n",
    "rows = cursor.fetchall()\n",
    "print(rows)\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Chris', '20210318004051', '03/11/2021', '12')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
